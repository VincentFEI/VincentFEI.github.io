<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ZhangPengfei CV Site</title>
    <link>https://zhangpengfei.com/</link>
      <atom:link href="https://zhangpengfei.com/index.xml" rel="self" type="application/rss+xml" />
    <description>ZhangPengfei CV Site</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Sun, 01 Sep 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://zhangpengfei.com/media/icon_hu7729264130191091259.png</url>
      <title>ZhangPengfei CV Site</title>
      <link>https://zhangpengfei.com/</link>
    </image>
    
    <item>
      <title>Spatial Temporal Decider</title>
      <link>https://zhangpengfei.com/project/spatial_temporal_decider/</link>
      <pubDate>Mon, 01 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/project/spatial_temporal_decider/</guid>
      <description>&lt;h2 id=&#34;1-background&#34;&gt;1 Background&lt;/h2&gt;
&lt;p&gt;In traditional autonomous driving decision-making and planning frameworks, a lateral-longitudinal hierarchical architecture is often employed. However, since lateral and longitudinal decisions are made independently within this framework, their performance is often suboptimal in scenarios requiring close coordination between path and speed.&lt;/p&gt;
&lt;p&gt;For example, when the ego vehicle is traveling at high speed and a social vehicle merges into its cruising lane ahead, merely responding with braking may exceed the vehicle&amp;rsquo;s deceleration limits. In such cases, close coordination between path and speed is essential. The vehicle must execute a lateral maneuver to evade into an adjacent lane while simultaneously braking longitudinally to mitigate risk.&lt;/p&gt;
&lt;p&gt;Such scenarios are common in driving environments. Therefore, to enhance the coordination between lateral and longitudinal motions, it is necessary to design a joint decision-making strategy for critical obstacles on top of the lateral-longitudinal hierarchical framework.&lt;/p&gt;
&lt;p&gt;During my tenure in Baidu, I designed two lateral-longitudinal decision-making modules, which are descirbed as follows.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Behavior Planner for Lane-Change Scenarios&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In our decision-making framework, the lane-change process is divided into two states: normal lane-changing and risk avoidance. Normal lane-changing refers to situations where the ego vehicle merges into the target lane between two vehicles without interaction risks with the following vehicle or other traffic participants. Risk avoidance, on the other hand, occurs when interaction risks arise during the merging process, such as aggressive behavior from the following vehicle, vehicles entering from side roads, or pedestrians crossing. In such cases, the ego vehicle enters a special risk avoidance state and switches back to normal lane-changing once the interaction risk disappears. The primary purpose of the behavior planner is to decide the optimal behavior for the ego vehicle during the risk avoidance state. It determines whether the vehicle should return to its original lane, drive along lane lines, or proceed with the merge. This modules aims to optimize passenger comfort while ensuring safety.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. Spatial-Temporal Nudge Decider&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In path planning, a core challenge is determining whether dynamic obstacles require a lateral response, as well as the extent and position of such a response. Properly lateral decision to dynamic obstacles can minimize unnecessary harsh braking and erratic path oscillations, thereby enhancing the safety of the ego vehicle. The primary objective of the spatial-temporal nudge decider is to calculate a reasonable heuristic speed profile. Based on this profile, it determines the interaction timing with dynamic obstacles and the bypass position for executing the lateral maneuver.&lt;/p&gt;
&lt;h2 id=&#34;2-technical-details&#34;&gt;2 Technical Details&lt;/h2&gt;
&lt;h3 id=&#34;21-sampling-or-search&#34;&gt;2.1 Sampling or Search&lt;/h3&gt;
&lt;p&gt;The core objective of lateral-longitudinal joint decision-making is to determine a safe and reasonable 3D coarse trajectory for the ego vehicle. The joint decision-making task can be regarded as a multivariable, non-convex, non-smooth optimization problem. Solving this type of problem is highly challenging. Despite the heuristic optimization algorithms, such as SVGD, the more commonly used techniques are sampling and search.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Sampling-Based Approach&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The basic framework using sampling-based method involves generating a series of 3D trajectories for the ego vehicle. Each sampled trajectory is evaluated, and the best one is selected. During the evaluation, it is also necessary to sample the motion of obstacles based on the ego vehicle’s trajectory to make more accurate assessments of the trajectory’s quality.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Search-Based Approach&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The basic framework using search-based method involves defining the state space, action space, and cost function, then using a search algorithm to find the optimal action sequence. Generally, actions can be divided into micro-actions and macro-actions: Micro-actions correspond to low-level control quantity (e.g., steering angle, acceleration) and are well-suited for graph-search algorithms like A*. Macro-actions correspond to higher-level behaviors (e.g., acceleration, deceleration, lane change, gentle braking, nudging) and are better suited for tree-search algorithms like MCTS.
To evaluate interactions with obstacles, obstacle states and actions can also be included in the state and action spaces. However, this significantly increases the problem’s complexity.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Comparison of Methods&lt;/strong&gt;
The sampling-based method offers the advantages of lower computational complexity and flexible cost function design. However, its main drawback is insufficient sampling coverage, which may result in missing feasible trajectories. Conversely, the search-based method has the advantage of exhaustive exploration of the solution space, theoretically enabling the identification of an optimal solution. However, its disadvantages include high computational complexity and less flexible cost function design.&lt;/p&gt;
&lt;p&gt;Relatively speaking, we believe the limitations of the sampling method in terms of coverage are easier to address. Joint decision-making does not require a globally optimal 3D trajectory; it only needs a set of diverse trajectories representing different motion modalities, from which a relatively optimal trajectory can be selected. The effective cost function design can mitigate the impact of sampling incompleteness. For example, instead of using exact collision detection that leads to non-continuous property, metrics such as relative distance can be used to create continuous cost functions.&lt;/p&gt;
&lt;h3 id=&#34;22-cost-evaluation&#34;&gt;2.2 Cost Evaluation&lt;/h3&gt;
&lt;p&gt;Cost evaluation is to answer one key question: How to select the best trajectory? Clearly, this is a fundamental challenge that no approach can avoid. This question can be addressed from two perspectives: 1. What costs should be considered? 2. How should these trajectory be compared according to these costs?&lt;/p&gt;
&lt;p&gt;For the first question, my answer is that at least five categories should be included: safety, comfort, efficiency, interaction, and human-likeness. The specific design of cost functions is not detailed here, as it often depends on the scenarios.&lt;/p&gt;
&lt;p&gt;The second question is more interseting. The simplest and most direct method is to combine all costs into a weighted sum and select the trajectory with the lowest total cost. This is the most common approach in many papers. However, this method can be disastrous in engineering. The problems with weighted combinations of costs include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lack of priority representation: It fails to reflect the relative importance of different cost categories.&lt;/li&gt;
&lt;li&gt;Incomparable costs: Different cost categories are inherently non-comparable, such as the collision and efficiency.&lt;/li&gt;
&lt;li&gt;Severe coupling: Adjusting cost weights affects a wide and uncontrollable range of outcomes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;RuleBook-Based Cost Evaluation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Our solution is adopting the RuleBook-based cost evaluation framework. A Rule refers to a cost function that takes a trajectory as input and outputs a cost value. A RuleBook is a collection of cost functions and their priority relationships. Let&amp;rsquo;s consider an example as illustrated below. Suppose we have three rules:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rule $\alpha$: corresponding to collision cost.&lt;/li&gt;
&lt;li&gt;Rule $\beta$: corresponding to harsh braking cost.&lt;/li&gt;
&lt;li&gt;Rule $\gamma$: corresponding to stagnation cost.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As shown in the below figure, the RuleBook defines their priority relationships. For instance, if Rule $\alpha$ has the highest priority, trajectories are first sorted by their collision cost. If three trajectories $x$, $y$, and $z$ are evaluated, we can get $x &lt; y$ and $x &lt; z$ based on Rule $\alpha$.However, the $y$ and $z$ cannot be distinguished based on Rules $\beta$ and $\gamma$, since these two rules do not have a priority relationship. To further compare the remain trajectories, the RuleBook can be adjusted in following ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set a priority relationship: Assign Rule  $\beta$ a lower priority than Rule $\gamma$, resulting in $z &lt; y$.&lt;/li&gt;
&lt;li&gt;Combine rules: Create a new rule $\delta$ by weighting Rules $\beta$ and $\gamma$, such that if  $\delta(z)&lt;\delta(y)$, then $z &lt; y$.&lt;/li&gt;
&lt;li&gt;Introduce a new trajectory or rule: If a fourth trajectory $w$ exists, and $\beta(z)=\beta(w),~\gamma(z)=\gamma(w)$, adding a low priority rule $\delta$ can distinguish between $z$ and $w$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the RuleBook-based cost evaluation framework, the priority of rules is explicitly defined. Adjustments to the RuleBook, such as adding new priorities, merging old rules, or introducing new rules, can clearly define the relative order of all trajectories. Additionally, an important advantages for this framework is adjusting lower-priority rules do not affect the relative order determined by higher-priority rules. This ensures that the scope of impact during algorithm iteration is well-controlled, making the system robust and adaptable.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Example of a RuleBook&#34; srcset=&#34;
               /project/spatial_temporal_decider/rulebook_hu10158784672624911263.webp 400w,
               /project/spatial_temporal_decider/rulebook_hu16855238804849058884.webp 760w,
               /project/spatial_temporal_decider/rulebook_hu3357020951016851953.webp 1200w&#34;
               src=&#34;https://zhangpengfei.com/project/spatial_temporal_decider/rulebook_hu10158784672624911263.webp&#34;
               width=&#34;760&#34;
               height=&#34;272&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;23-uncertainty-in-obstacle-motion&#34;&gt;2.3 Uncertainty in Obstacle Motion&lt;/h3&gt;
&lt;p&gt;Handling uncertainty in obstacle motion is one of the most challenging issues in autonomous driving decision-making systems. This uncertainty has two key dimensions: intent uncertainty and trajectory uncertainty. For example, consider a scenario shown in cover figure, where the ego vehicle is driving straight, and a vehicle emerges from a side road ahead. The intent of this vehicle is unclear, it may either cut in immediately or wait for the ego vehicle to pass. For an autonomous driving system, assuming the vehicle will cut in may result in harsh braking, while assuming it will yield may lead to a collision risk. Driving like a human, such as slowing down to observe the other vehicle’s intent before making the next decision, is a key algorithmic challenge. Even when the intent of the obstacle is clear, its future trajectory remains uncertain. The cut-in angle and timing of that vehicle cannot be precisely predicted. Therefore, ensuring safety under trajectory uncertainty is another critical consideration for decision-making algorithms. Based on our understanding of existing methods, we believe contingency planning is well-suited for addressing intent uncertainty, while risk metrics from stochastic programming can be effective in handling trajectory uncertainty.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contingency Planning for Intent Uncertainty&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The core idea of contingency planning is to construct a trajectory tree that considers multiple obstacle intents simultaneously, as illustrated in cover figure. Each branch of the tree corresponds to a specific intent of the obstacle. This method evaluates the overall cost of the trajectory tree by combining the probability distribution of obstacle intents with the cost of each branch. Under the contingency planning framework, the ego vehicle responds to all possible obstacle intents. For intents with lower probabilities, the vehicle’s response is minimal, while for intents with higher probabilities, the response is stronger. This means that temporary uncertainty in obstacle intent is acceptable. As time progresses and the probability distribution of obstacle intents converges to the true intent, the ego vehicle’s behavior will become reasonable.&lt;/p&gt;
&lt;p&gt;It is worth noting that partially observable Markov decision processes (POMDP) also offer a problem formulation for addressing intent uncertainty. POMDP can explicitly define actions that gather information and reduce uncertainty. Thus, the ego vehicle has the capability to adopt a defensive driving maneuver to address uncertain driving scenarios.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Risk Metrics in Stochastic Programming for Trajectory Uncertainty&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The core idea of using risk metrics to address trajectory uncertainty is to evaluate collision costs from a probabilistic perspective. Traditional methods compute collision costs by performing exact collision detection between the ego vehicle&amp;rsquo;s trajectory and the predicted obstacle trajectory. However, such detection are highly sensitive to changes in predicted trajectories, resulting in abrupt cost jumps. When trajectory uncertainty is significant, the exact collision detection becomes meaningless.&lt;/p&gt;
&lt;p&gt;Introducing Value at Risk (VaR) or Conditional Value at Risk (CVaR) can address this issue. By incorporating these metric as objective functions or constraints, collision risks can be controlled at a given confidence level.&lt;/p&gt;
&lt;p&gt;For instance, let $x$ represent the ego vehicle’s trajectory, $\xi$ represent the obstacle trajectory (a random variable), and $G(x, \xi)$ represent the overlap area between the two trajectories (also a random variable). The metric $\text{VaR}_{1-\alpha}[G(x, \xi)]$ is defined as a value $t$ such that the probability of $G(x, \xi) &gt; t$ is $\alpha$, and the probability of $G(x,\xi) &lt; t$ is $1-\alpha$.&lt;/p&gt;
&lt;p&gt;Based on this definition, a smaller $\text{VaR}_{1-\alpha}[G(x, \xi)]$ at a fixed confidence level $\alpha$ indicates a higher probability of smaller overlap areas between the trajectories, implying greater safetyEmploying VaR as a collision cost provides a probabilistic guarantee of safety.&lt;/p&gt;
&lt;p&gt;Of course, calculating VaR is complex and requires specialized design for practical applications. Nonetheless, these risk metrics allow decision-making algorithms to manage trajectory uncertainty effectively and robustly.&lt;/p&gt;
&lt;!-- ## 3 Result

The behavior planner for lane-change scenarios and the spatiotemporal nudge decider have been extensively integrated into our decision module, significantly enhancing driving rationality and comfort. --&gt;
</description>
    </item>
    
    <item>
      <title>Auto-Generation of Mission-Oriented Robot Controllers Using Bayesian-Based Koopman Operator</title>
      <link>https://zhangpengfei.com/publication/tro2023/</link>
      <pubDate>Mon, 18 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/publication/tro2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>🎉 Easily create your own simple yet highly customizable blog</title>
      <link>https://zhangpengfei.com/post/get-started/</link>
      <pubDate>Fri, 27 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/post/get-started/</guid>
      <description>&lt;p&gt;Welcome 👋&lt;/p&gt;



&lt;details class=&#34;print:hidden xl:hidden&#34; open&gt;
  &lt;summary&gt;Table of Contents&lt;/summary&gt;
  &lt;div class=&#34;text-sm&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#overview&#34;&gt;Overview&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#get-started&#34;&gt;Get Started&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#crowd-funded-open-source-software&#34;&gt;Crowd-funded open-source software&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#-click-here-to-become-a-sponsor-and-help-support-hugo-bloxs-future-httpshugobloxcomsponsor&#34;&gt;&lt;a href=&#34;https://hugoblox.com/sponsor/&#34;&gt;❤️ Click here to become a sponsor and help support Hugo Blox&amp;rsquo;s future ❤️&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#ecosystem&#34;&gt;Ecosystem&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#inspiration&#34;&gt;Inspiration&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#themes&#34;&gt;Themes&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
  &lt;/div&gt;
&lt;/details&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;The Hugo Blox website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site&lt;/li&gt;
&lt;li&gt;The template can be modified and customised to suit your needs. It&amp;rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a &lt;strong&gt;no-code solution (write in Markdown and customize with YAML parameters)&lt;/strong&gt; and having &lt;strong&gt;flexibility to later add even deeper personalization with HTML and CSS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;get-started&#34;&gt;Get Started&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;👉 
&lt;/li&gt;
&lt;li&gt;📚 
&lt;/li&gt;
&lt;li&gt;💬 
 or 
&lt;/li&gt;
&lt;li&gt;🐦 Twitter: 
 
 #MadeWithHugoBlox&lt;/li&gt;
&lt;li&gt;💡 
&lt;/li&gt;
&lt;li&gt;⬆️ &lt;strong&gt;Updating Hugo Blox?&lt;/strong&gt; View the 
 and 
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;crowd-funded-open-source-software&#34;&gt;Crowd-funded open-source software&lt;/h2&gt;
&lt;p&gt;To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.&lt;/p&gt;
&lt;h3 id=&#34;-click-here-to-become-a-sponsor-and-help-support-hugo-bloxs-future-httpshugobloxcomsponsor&#34;&gt;
&lt;/h3&gt;
&lt;p&gt;As a token of appreciation for sponsoring, you can &lt;strong&gt;unlock 
 awesome rewards and extra features 🦄✨&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;ecosystem&#34;&gt;Ecosystem&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;
:&lt;/strong&gt; Automatically import publications from BibTeX&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;inspiration&#34;&gt;Inspiration&lt;/h2&gt;
&lt;p&gt;
 are building with this template.&lt;/p&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Page builder&lt;/strong&gt; - Create &lt;em&gt;anything&lt;/em&gt; with no-code 
 and 
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Edit any type of content&lt;/strong&gt; - Blog posts, publications, talks, slides, projects, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create content&lt;/strong&gt; in 
, 
, or 
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plugin System&lt;/strong&gt; - Fully customizable 
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Display Code and Math&lt;/strong&gt; - Code syntax highlighting and LaTeX math supported&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integrations&lt;/strong&gt; - 
, 
, Maps, Contact Forms, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Beautiful Site&lt;/strong&gt; - Simple and refreshing one-page design&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Industry-Leading SEO&lt;/strong&gt; - Help get your website found on search engines and social media&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Media Galleries&lt;/strong&gt; - Display your images and videos with captions in a customizable gallery&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mobile Friendly&lt;/strong&gt; - Look amazing on every screen with a mobile friendly version of your site&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-language&lt;/strong&gt; - 35+ language packs including English, 中文, and Português&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-user&lt;/strong&gt; - Each author gets their own profile page&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Privacy Pack&lt;/strong&gt; - Assists with GDPR&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stand Out&lt;/strong&gt; - Bring your site to life with animation, parallax backgrounds, and scroll effects&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;One-Click Deployment&lt;/strong&gt; - No servers. No databases. Only files.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;p&gt;Hugo Blox and its templates come with &lt;strong&gt;automatic day (light) and night (dark) mode&lt;/strong&gt; built-in. Visitors can choose their preferred mode by clicking the sun/moon icon in the header.&lt;/p&gt;
&lt;p&gt;
 for your site. Themes are fully customizable.&lt;/p&gt;
&lt;h2 id=&#34;license&#34;&gt;License&lt;/h2&gt;
&lt;p&gt;Copyright 2016-present 
.&lt;/p&gt;
&lt;p&gt;Released under the 
 license.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>🧠 Sharpen your thinking with a second brain</title>
      <link>https://zhangpengfei.com/post/second-brain/</link>
      <pubDate>Thu, 26 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/post/second-brain/</guid>
      <description>&lt;p&gt;Create a personal knowledge base and share your knowledge with your peers.&lt;/p&gt;
&lt;p&gt;Hugo Blox web framework empowers you with one of the most flexible note-taking capabilities out there.&lt;/p&gt;
&lt;p&gt;Create a powerful knowledge base that works on top of a local folder of plain text Markdown files.&lt;/p&gt;
&lt;p&gt;Use it as your second brain, either publicly sharing your knowledge with your peers via your website, or via a private GitHub repository and password-protected site just for yourself.&lt;/p&gt;
&lt;h2 id=&#34;mindmaps&#34;&gt;Mindmaps&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports a Markdown extension for mindmaps.&lt;/p&gt;
&lt;p&gt;With this open format, can even edit your mindmaps in other popular tools such as Obsidian.&lt;/p&gt;
&lt;p&gt;Simply insert a Markdown code block labelled as &lt;code&gt;markmap&lt;/code&gt; and optionally set the height of the mindmap as shown in the example below.&lt;/p&gt;
&lt;p&gt;Mindmaps can be created by simply writing the items as a Markdown list within the &lt;code&gt;markmap&lt;/code&gt; code block, indenting each item to create as many sub-levels as you need:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;
&lt;code&gt;
```markmap {height=&#34;200px&#34;}
- Hugo Modules
  - Hugo Blox
  - blox-plugins-netlify
  - blox-plugins-netlify-cms
  - blox-plugins-reveal
```
&lt;/code&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;markmap&#34; style=&#34;height: 200px;&#34;&gt;

&lt;pre&gt;- Hugo Modules
  - Hugo Blox
  - blox-plugins-netlify
  - blox-plugins-netlify-cms
  - blox-plugins-reveal&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Anh here&amp;rsquo;s a more advanced mindmap with formatting, code blocks, and math:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;
&lt;code&gt;
```markmap
- Mindmaps
  - Links
    - [Hugo Blox Docs](https://docs.hugoblox.com/)
    - [Discord Community](https://discord.gg/z8wNYzb)
    - [GitHub](https://github.com/HugoBlox/hugo-blox-builder)
  - Features
    - Markdown formatting
    - **inline** ~~text~~ *styles*
    - multiline
      text
    - `inline code`
    -
      ```js
      console.log(&#39;hello&#39;);
      console.log(&#39;code block&#39;);
      ```
    - Math: $x = {-b \pm \sqrt{b^2-4ac} \over 2a}$
```
&lt;/code&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;markmap&#34; style=&#34;height: 500px;&#34;&gt;

&lt;pre&gt;- Mindmaps
  - Links
    - [Hugo Blox Docs](https://docs.hugoblox.com/)
    - [Discord Community](https://discord.gg/z8wNYzb)
    - [GitHub](https://github.com/HugoBlox/hugo-blox-builder)
  - Features
    - Markdown formatting
    - **inline** ~~text~~ *styles*
    - multiline
      text
    - `inline code`
    -
      ```js
      console.log(&#39;hello&#39;);
      console.log(&#39;code block&#39;);
      ```
    - Math: $x = {-b \pm \sqrt{b^2-4ac} \over 2a}$&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&#34;highlighting&#34;&gt;Highlighting&lt;/h2&gt;
&lt;p&gt;&lt;mark&gt;Highlight&lt;/mark&gt; important text with &lt;code&gt;mark&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mark&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;Highlighted text&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mark&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;callouts&#34;&gt;Callouts&lt;/h2&gt;
&lt;p&gt;Use 
 (aka &lt;em&gt;asides&lt;/em&gt;, &lt;em&gt;hints&lt;/em&gt;, or &lt;em&gt;alerts&lt;/em&gt;) to draw attention to notes, tips, and warnings.&lt;/p&gt;
&lt;p&gt;By wrapping a paragraph in &lt;code&gt;{{% callout note %}} ... {{% /callout %}}&lt;/code&gt;, it will render as an aside.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% callout note %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;A Markdown aside is useful for displaying notices, hints, or definitions to your readers.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% /callout %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;A Markdown aside is useful for displaying notices, hints, or definitions to your readers.&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;Or use the &lt;code&gt;warning&lt;/code&gt; callout type so your readers don&amp;rsquo;t miss critical details:&lt;/p&gt;
&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-yellow-100 dark:bg-yellow-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-red-400&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;M12 9v3.75m-9.303 3.376c-.866 1.5.217 3.374 1.948 3.374h14.71c1.73 0 2.813-1.874 1.948-3.374L13.949 3.378c-.866-1.5-3.032-1.5-3.898 0zM12 15.75h.007v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;A Markdown aside is useful for displaying notices, hints, or definitions to your readers.&lt;/span&gt;
&lt;/div&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>📈 Communicate your results effectively with the best data visualizations</title>
      <link>https://zhangpengfei.com/post/data-visualization/</link>
      <pubDate>Wed, 25 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/post/data-visualization/</guid>
      <description>&lt;p&gt;Hugo Blox is designed to give technical content creators a seamless experience. You can focus on the content and Hugo Blox handles the rest.&lt;/p&gt;
&lt;p&gt;Use popular tools such as Plotly, Mermaid, and data frames.&lt;/p&gt;
&lt;h2 id=&#34;charts&#34;&gt;Charts&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports the popular 
 format for interactive data visualizations. With Plotly, you can design almost any kind of visualization you can imagine!&lt;/p&gt;
&lt;p&gt;Save your Plotly JSON in your page folder, for example &lt;code&gt;line-chart.json&lt;/code&gt;, and then add the &lt;code&gt;{{&amp;lt; chart data=&amp;quot;line-chart&amp;quot; &amp;gt;}}&lt;/code&gt; shortcode where you would like the chart to appear.&lt;/p&gt;
&lt;p&gt;Demo:&lt;/p&gt;




&lt;div id=&#34;chart-197462358&#34; class=&#34;chart&#34;&gt;&lt;/div&gt;
&lt;script&gt;
  async function fetchChartJSON() {
    console.debug(&#39;Hugo Blox fetching chart JSON...&#39;)
    const response = await fetch(&#39;.\/line-chart.json&#39;);
    return await response.json();
  }

  (function() {
    let a = setInterval( function() {
      if ( typeof window.Plotly === &#39;undefined&#39; ) {
        console.debug(&#39;Plotly not loaded yet...&#39;)
        return;
      }
      clearInterval( a );

      fetchChartJSON().then(chart =&gt; {
        console.debug(&#39;Plotting chart...&#39;)
        window.Plotly.newPlot(&#39;chart-197462358&#39;, chart.data, chart.layout, {responsive: true});
      });
    }, 500 );
  })();
&lt;/script&gt;

&lt;p&gt;You might also find the 
 useful.&lt;/p&gt;
&lt;h2 id=&#34;diagrams&#34;&gt;Diagrams&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports the &lt;em&gt;Mermaid&lt;/em&gt; Markdown extension for diagrams.&lt;/p&gt;
&lt;p&gt;An example &lt;strong&gt;flowchart&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
graph TD
A[Hard] --&amp;gt;|Text| B(Round)
B --&amp;gt; C{Decision}
C --&amp;gt;|One| D[Result 1]
C --&amp;gt;|Two| E[Result 2]
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;graph TD
A[Hard] --&gt;|Text| B(Round)
B --&gt; C{Decision}
C --&gt;|One| D[Result 1]
C --&gt;|Two| E[Result 2]
&lt;/div&gt;
&lt;p&gt;An example &lt;strong&gt;sequence diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
sequenceDiagram
Alice-&amp;gt;&amp;gt;John: Hello John, how are you?
loop Healthcheck
    John-&amp;gt;&amp;gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts!
John--&amp;gt;&amp;gt;Alice: Great!
John-&amp;gt;&amp;gt;Bob: How about you?
Bob--&amp;gt;&amp;gt;John: Jolly good!
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;sequenceDiagram
Alice-&gt;&gt;John: Hello John, how are you?
loop Healthcheck
    John-&gt;&gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts!
John--&gt;&gt;Alice: Great!
John-&gt;&gt;Bob: How about you?
Bob--&gt;&gt;John: Jolly good!
&lt;/div&gt;
&lt;p&gt;An example &lt;strong&gt;class diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
classDiagram
Class01 &amp;lt;|-- AveryLongClass : Cool
Class03 *-- Class04
Class05 o-- Class06
Class07 .. Class08
Class09 --&amp;gt; C2 : Where am i?
Class09 --* C3
Class09 --|&amp;gt; Class07
Class07 : equals()
Class07 : Object[] elementData
Class01 : size()
Class01 : int chimp
Class01 : int gorilla
Class08 &amp;lt;--&amp;gt; C2: Cool label
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;classDiagram
Class01 &lt;|-- AveryLongClass : Cool
Class03 *-- Class04
Class05 o-- Class06
Class07 .. Class08
Class09 --&gt; C2 : Where am i?
Class09 --* C3
Class09 --|&gt; Class07
Class07 : equals()
Class07 : Object[] elementData
Class01 : size()
Class01 : int chimp
Class01 : int gorilla
Class08 &lt;--&gt; C2: Cool label
&lt;/div&gt;
&lt;p&gt;An example &lt;strong&gt;state diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
stateDiagram
[*] --&amp;gt; Still
Still --&amp;gt; [*]
Still --&amp;gt; Moving
Moving --&amp;gt; Still
Moving --&amp;gt; Crash
Crash --&amp;gt; [*]
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;stateDiagram
[*] --&gt; Still
Still --&gt; [*]
Still --&gt; Moving
Moving --&gt; Still
Moving --&gt; Crash
Crash --&gt; [*]
&lt;/div&gt;
&lt;h2 id=&#34;data-frames&#34;&gt;Data Frames&lt;/h2&gt;
&lt;p&gt;Save your spreadsheet as a CSV file in your page&amp;rsquo;s folder and then render it by adding the &lt;em&gt;Table&lt;/em&gt; shortcode to your page:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&amp;lt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;table&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;results.csv&amp;#34;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;header&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;caption&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Table 1: My results&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;














&lt;table class=&#34;table-auto w-full&#34;&gt;
  
    
    
    &lt;thead&gt;
      &lt;tr&gt;  &lt;th class=&#34;border-b dark:border-slate-600 font-medium p-4 pt-0 pb-3 text-slate-400 dark:text-slate-200 text-left&#34;&gt;customer_id&lt;/th&gt;  &lt;th class=&#34;border-b dark:border-slate-600 font-medium p-4 pt-0 pb-3 text-slate-400 dark:text-slate-200 text-left&#34;&gt;score&lt;/th&gt;  &lt;/tr&gt;
    &lt;/thead&gt;
  
  &lt;tbody&gt;
  
    &lt;tr&gt;
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;1&lt;/td&gt;
        
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;0&lt;/td&gt;
        
      
    &lt;/tr&gt;
  
    &lt;tr&gt;
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;2&lt;/td&gt;
        
      
        
          &lt;td data-table-dtype=&#34;text&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;0.5&lt;/td&gt;
        
      
    &lt;/tr&gt;
  
    &lt;tr&gt;
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;3&lt;/td&gt;
        
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;1&lt;/td&gt;
        
      
    &lt;/tr&gt;
  
  &lt;/tbody&gt;
  
    &lt;caption class=&#34;table-caption&#34;&gt;Table 1: My results&lt;/caption&gt;
  
&lt;/table&gt;

&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>👩🏼‍🏫 Teach academic courses</title>
      <link>https://zhangpengfei.com/post/teach-courses/</link>
      <pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/post/teach-courses/</guid>
      <description>&lt;p&gt;
 is designed to give technical content creators a seamless experience. You can focus on the content and the Hugo Blox Builder which this template is built upon handles the rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Embed videos, podcasts, code, LaTeX math, and even test students!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On this page, you&amp;rsquo;ll find some examples of the types of technical content that can be rendered with Hugo Blox.&lt;/p&gt;
&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;
&lt;p&gt;Teach your course by sharing videos with your students. Choose from one of the following approaches:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Youtube&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; youtube 1YwS2vIkxRs &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/1YwS2vIkxRs?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Bilibili&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; bilibili BV1WV4y1r7DF &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;w-full h-auto aspect-video relative&#34;&gt;
  &lt;iframe src=&#34;//player.bilibili.com/player.html?bvid=BV1WV4y1r7DF&amp;page=1&#34;
  allow=&#34;accelerometer; clipboard-write; encrypted-media; gyroscope; fullscreen; picture-in-picture;&#34;
  class=&#34;w-full h-full&#34;
  &gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Video file&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Videos may be added to a page by either placing them in your &lt;code&gt;assets/media/&lt;/code&gt; media library or in your 
, and then embedding them with the &lt;em&gt;video&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; video src=&amp;quot;my_video.mp4&amp;quot; controls=&amp;quot;yes&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;podcast&#34;&gt;Podcast&lt;/h2&gt;
&lt;p&gt;You can add a podcast or music to a page by placing the MP3 file in the page&amp;rsquo;s folder or the media library folder and then embedding the audio on your page with the &lt;em&gt;audio&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; audio src=&amp;quot;ambient-piano.mp3&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Try it out:&lt;/p&gt;








  








&lt;audio controls &gt;
  &lt;source src=&#34;https://zhangpengfei.com/post/teach-courses/ambient-piano.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;

&lt;h2 id=&#34;test-students&#34;&gt;Test students&lt;/h2&gt;
&lt;p&gt;Provide a simple yet fun self-assessment by revealing the solutions to challenges with the &lt;code&gt;spoiler&lt;/code&gt; shortcode:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;👉 Click to view the solution&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;You found me!
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary class=&#34;cursor-pointer&#34;&gt;👉 Click to view the solution&lt;/summary&gt;
  &lt;div class=&#34;rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2&#34;&gt;
    You found me 🎉
  &lt;/div&gt;
&lt;/details&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder supports a Markdown extension for $\LaTeX$ math. Enable math by setting the &lt;code&gt;math: true&lt;/code&gt; option in your page&amp;rsquo;s front matter, or enable math for your entire site by toggling math in your &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;math&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To render &lt;em&gt;inline&lt;/em&gt; or &lt;em&gt;block&lt;/em&gt; math, wrap your LaTeX math with &lt;code&gt;$...$&lt;/code&gt; or &lt;code&gt;$$...$$&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;math block&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\gamma&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{ &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; | &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^T &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; |}{&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
$$\gamma_{n} = \frac{ \left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T \left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}{\left \|\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right \|^2}$$&lt;p&gt;Example &lt;strong&gt;inline math&lt;/strong&gt; &lt;code&gt;$\nabla F(\mathbf{x}_{n})$&lt;/code&gt; renders as $\nabla F(\mathbf{x}_{n})$.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;multi-line math&lt;/strong&gt; using the math linebreak (&lt;code&gt;\\&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;k;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;, &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
$$
f(k;p_{0}^{*}) = \begin{cases}p_{0}^{*} &amp; \text{if }k=1, \\
1-p_{0}^{*} &amp; \text{if }k=0.\end{cases}
$$&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder utilises Hugo&amp;rsquo;s Markdown extension for highlighting code syntax. The code theme can be selected in the &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```python
import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;data.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;inline-images&#34;&gt;Inline Images&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&amp;lt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;icon&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;}}&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; height=&#34;1em&#34; viewBox=&#34;0 0 448 512&#34; fill=&#34;currentColor&#34;&gt;&lt;path d=&#34;M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6zM286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3zM167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4zm-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3z&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; Python&lt;/p&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>✅ Manage your projects</title>
      <link>https://zhangpengfei.com/post/project-management/</link>
      <pubDate>Mon, 23 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/post/project-management/</guid>
      <description>&lt;p&gt;Easily manage your projects - create ideation mind maps, Gantt charts, todo lists, and more!&lt;/p&gt;
&lt;h2 id=&#34;ideation&#34;&gt;Ideation&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports a Markdown extension for mindmaps.&lt;/p&gt;
&lt;p&gt;Simply insert a Markdown code block labelled as &lt;code&gt;markmap&lt;/code&gt; and optionally set the height of the mindmap as shown in the example below.&lt;/p&gt;
&lt;p&gt;Mindmaps can be created by simply writing the items as a Markdown list within the &lt;code&gt;markmap&lt;/code&gt; code block, indenting each item to create as many sub-levels as you need:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;
&lt;code&gt;
```markmap {height=&#34;200px&#34;}
- Hugo Modules
  - Hugo Blox
  - blox-plugins-netlify
  - blox-plugins-netlify-cms
  - blox-plugins-reveal
```
&lt;/code&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;markmap&#34; style=&#34;height: 200px;&#34;&gt;

&lt;pre&gt;- Hugo Modules
  - Hugo Blox
  - blox-plugins-netlify
  - blox-plugins-netlify-cms
  - blox-plugins-reveal&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&#34;diagrams&#34;&gt;Diagrams&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports the &lt;em&gt;Mermaid&lt;/em&gt; Markdown extension for diagrams.&lt;/p&gt;
&lt;p&gt;An example &lt;strong&gt;Gantt diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
gantt
section Section
Completed :done,    des1, 2014-01-06,2014-01-08
Active        :active,  des2, 2014-01-07, 3d
Parallel 1   :         des3, after des1, 1d
Parallel 2   :         des4, after des1, 1d
Parallel 3   :         des5, after des3, 1d
Parallel 4   :         des6, after des4, 1d
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;gantt
section Section
Completed :done,    des1, 2014-01-06,2014-01-08
Active        :active,  des2, 2014-01-07, 3d
Parallel 1   :         des3, after des1, 1d
Parallel 2   :         des4, after des1, 1d
Parallel 3   :         des5, after des3, 1d
Parallel 4   :         des6, after des4, 1d
&lt;/div&gt;
&lt;h2 id=&#34;todo-lists&#34;&gt;Todo lists&lt;/h2&gt;
&lt;p&gt;You can even write your todo lists in Markdown too:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;- [x]&lt;/span&gt; Write math example
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;- [x]&lt;/span&gt; Write diagram example
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;- [ ]&lt;/span&gt; Do something else
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write math example
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write diagram example&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Do something else&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Cartesian Path Planner</title>
      <link>https://zhangpengfei.com/project/path_planner/</link>
      <pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/project/path_planner/</guid>
      <description>&lt;h3 id=&#34;1-background&#34;&gt;1 Background&lt;/h3&gt;
&lt;p&gt;Traditional path planning methods based on the Frenet coordinate system have advantages such as simple problem formulation and fast solving speed. However, they also suffer from significant drawbacks, including a heavy reliance on the reference line, overly complex curvature constraints, difficulty in evaluating ride comfort, and highly inaccurate modeling of collision constraints.&lt;/p&gt;
&lt;p&gt;To address these issues, we propose a path planning approach in the Cartesian coordinate system. The Cartesian-based method offers advantages such as the ability to incorporate precise vehicle kinematic constraints, curvature constraints, and collision constraints, making it easier to ensure the feasibility and safety of the path. However, path planning in the Cartesian coordinate system also faces several challenges. For instance, kinematic constraints become nonlinear equality constraints, collision constraints shift from convex to non-convex, and the reference line cost transitions from a simple quadratic function to a complex nonlinear form. These characteristics result in the optimization problem having numerous local minima, increasing reliance on the initial solution and imposing higher demands on the convergence and solving speed of the optimization algorithm.&lt;/p&gt;
&lt;h3 id=&#34;2-technical-details&#34;&gt;2 Technical Details&lt;/h3&gt;
&lt;h4 id=&#34;21-path-representation&#34;&gt;2.1 Path Representation&lt;/h4&gt;
&lt;p&gt;Common path representations in autonomous driving include Bézier curves, B-spline curves, spiral curves, and vehicle kinematic models. In our approach, we adopt the kinematic model, using $\dot\kappa$ as the control input and $X$, $Y$, $\theta$, and $\kappa$ as the system states. Compared to other methods, this path representation offers significant flexibility and allows for straightforward constraints on $\kappa$ and $\dot\kappa$. However, it has a notable drawback: ensuring path smoothness is challenging, as it is influenced by other cost functions and constraints.&lt;/p&gt;
&lt;h4 id=&#34;22-collision-constraint-modeling&#34;&gt;2.2 Collision Constraint Modeling&lt;/h4&gt;
&lt;p&gt;This involves two aspects of selection: the representation of the ego vehicle and the representation of the environment. These two factors also influence each other.&lt;/p&gt;
&lt;p&gt;For the representation of the ego vehicle, it can be modeled as a convex polygon, typically a rectangle, or as a union of multiple enclosing circles. Generally, the convex polygon representation is more accurate than the enclosing circle method. However, calculating the distance between a convex polygon and obstacles is significantly more complex than calculating the distance between enclosing circles and obstacles.&lt;/p&gt;
&lt;p&gt;For the representation of the environment, there are three main approaches:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Direct Representation&lt;/strong&gt;: Obstacles are modeled as convex hulls, such as convex polygons, spheres, or ellipsoids.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Drivable Corridor Representation&lt;/strong&gt;: Drivable regions are represented as a union of convex sets, such as convex polygons or spheres.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Distance Field Representation&lt;/strong&gt;: A global distance function is constructed, where the input is a coordinate, and the output is the distance from this coordinate to the nearest obstacle. The typical representation is Euclidean Signed Distance Field (ESDF).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each of these methods has its advantages and disadvantages.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The first approach requires few assumptions, preserving the original feasible space to the greatest extent. However, it involves complex distance calculations and is inefficient when there are many obstacles.&lt;/li&gt;
&lt;li&gt;The second approach confines the solution within a drivable space. Each segment of the solution corresponds to a convex constraint, greatly simplifying the constraint of the problem. However, constructing the convex corridor is time-consuming, often loses significant drivable space, and the allocation of appropriate convex constraints to each segment heavily impacts the final solution.&lt;/li&gt;
&lt;li&gt;The third approach is highly efficient, with the time complexity for distance and gradient calculations based on the distance field being O(1). However, building the distance field is time-consuming, and its resolution greatly affects the resulting path.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ultimately, we opted for the enclosing circle representation for the ego vehicle, sacrificing some accuracy to achieve lower computational complexity. For the environment representation, we experimented with both the drivable corridor and Euclidean distance field approaches and chose the Euclidean distance field method. This section provides a high-level overview of the technical choices. In practical implementation, regardless of the chosen representation method, numerous engineering techniques and algorithmic improvements are required to achieve an better result.&lt;/p&gt;
&lt;h4 id=&#34;23-reference-line-cost-modeling&#34;&gt;2.3 Reference Line Cost Modeling&lt;/h4&gt;
&lt;p&gt;Before introducing the specific modeling approach, it is essential to clarify the complexity of reference line costs. In the Frenet coordinate system, the reference line cost is a simple quadratic function:&lt;br&gt;
&lt;/p&gt;
$$
\min_L \frac{1}{2} w_l L^2
$$&lt;p&gt;&lt;br&gt;
However, in the Cartesian coordinate system, this cost function becomes much more complex. In fact, the reference line cost can be generalized to achieve the same optimization goals as in the Frenet system, which is essentially a cost designed for the $(S, L)$ variables. For instance, the reference line cost in the Cartesian system can be expressed as:&lt;br&gt;
&lt;/p&gt;
$$
\min_{X, Y} \frac{1}{2} w_l L(X, Y)^2
$$&lt;p&gt;&lt;br&gt;
where $L(X,Y)$ is a Frenet projection function of $X$ and $Y$.&lt;/p&gt;
&lt;p&gt;Generally, projecting Cartesian coordinates $(X, Y)$ into Frenet coordinates $(S, L)$ involves two main steps. The first step determines the corresponding $S$ by identifying the nearest point on the reference line to $(X, Y)$. The second step computes $L$ based on the normal vector of the reference line at $S$.&lt;/p&gt;
&lt;p&gt;For the first step, the common engineering approach is to traverse all points on the reference line to find the nearest one and use its $S$ coordinate as the projection result. For the second step, assume the reference line point at $S$ has coordinates $[X(S), Y(S)]$ and a normal vector $[N_X(S), N_Y(S)]$. Then, $L(X, Y)$ can be calculated as:&lt;br&gt;
&lt;/p&gt;
$$
L(X, Y) = \left[X - X(S), Y - Y(S)\right] \cdot 
\left[\begin{matrix}N_X(S)\\ N_Y(S)\end{matrix}\right]
$$&lt;p&gt;Based on the above, modeling the reference line cost, as well as other Frenet optimization objectives, primarily involves efficiently determining the $(S, L)$ values corresponding to $(X, Y)$ and quickly computing the gradients $\frac{dS}{dX}, \frac{dS}{dY}, \frac{dL}{dX}, \frac{dL}{dY}$.&lt;/p&gt;
&lt;p&gt;Two feasible methods address this objective:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fixed Nearest Point Approach:&lt;/strong&gt;&lt;br&gt;
For each path point in the initial solution, search for the nearest point and fix its $S$ value for the subsequent optimization process. The advantage of this approach is that $\frac{dS}{dX} = 0$ and $\frac{dS}{dY} = 0$, simplifying the reference line cost. However, the drawback is that when there is a significant difference between the initial solution and the optimal solution, the initially assigned $S$ value may deviate greatly from the accurate $S$, leading to a final solution that does not align with the intended cost design.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Precomputed SLMap Approach:&lt;/strong&gt;&lt;br&gt;
Before optimization, precompute an SLMap, a function that maps $(X, Y)$ inputs to $(S, L)$ outputs. The advantage of this method is that it avoids any prior assumptions and allows for very fast queries. However, constructing this map is time-intensive. Additionally, for the reference line cost specifically, it is sufficient to compute the projection relationship between $L$ and $(X, Y)$. This can be replaced by using a Euclidean distance field constructed based on the reference line.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;24-optimization-algorithm&#34;&gt;2.4 Optimization Algorithm&lt;/h4&gt;
&lt;p&gt;Path optimization in the Cartesian coordinate system can be formulated as a special type of constrained optimization problem, characterized primarily by chained equality constraints. Depending on the path representation, these constraints manifest as different kinematic or curve continuity constraints. In essence, this is treated as an optimal control problem.&lt;/p&gt;
&lt;p&gt;There are two main approaches to solving optimal control problems: collocation methods and shooting methods.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Collocation Method&lt;/strong&gt;:&lt;br&gt;
Collocation methods optimize both state variables and control variables simultaneously, treating kinematic constraints as general equality constraints. This approach is similar to how general constrained optimization problems are handled. Collocation methods are more numerically stable, less sensitive to the initial solution, and more easily to converge. However, they may not strictly satisfy kinematic constraints, involve more optimization variables, and have higher computational complexity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Shooting Method&lt;/strong&gt;:&lt;br&gt;
Shooting methods optimize only the control variables, while the state variables are propagated through the kinematic constraints. This ensures that kinematic constraints are strictly satisfied. Compared to collocation methods, shooting methods involve fewer optimization variables but are more sensitive to the initial solution and are prone to divergence.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Iterative Linear Quadratic Regulator (ILQR) algorithm is a classic example of a shooting method and is one of the most widely used optimization algorithms in the autonomous driving. Its advantages include the ability to strictly satisfy kinematic constraints and the use of dynamic programming to decompose a large-scale optimization problem into many smaller problems, thereby reducing complexity. However, its drawbacks include susceptibility to divergence, poor stability, and a lack of mechanisms to handle constraints other than kinematic ones.&lt;/p&gt;
&lt;p&gt;The ILQR algorithm was likely first popularized at Waymo, leading many domestic companies to adopt it. However, it might not be the most suitable optimization algorithm in all scenarios. In practical engineering implementations, applying the ILQR algorithm effectively often requires additional mechanisms for constraint handling (e.g., penalty functions or augmented Lagrangian methods), multiple shooting techniques, and trust region methods.&lt;/p&gt;
&lt;h3 id=&#34;3-engineering-techniques&#34;&gt;3 Engineering Techniques&lt;/h3&gt;
&lt;h4 id=&#34;31-problem-modeling&#34;&gt;3.1 Problem Modeling&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Selection of Enclosing Circle Position, Number, and Radius:&lt;/strong&gt;&lt;br&gt;
The position, radius, and number of enclosing circles need to balance accuracy and efficiency. For path planning, the enclosing circles should not cover the entire vehicle body, but rather the entire path. From this perspective, we can reduce both the radius and the number of enclosing circles.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Polyline Boundary Smoothing Method:&lt;/strong&gt;&lt;br&gt;
For path planning, assuming that left and right boundaries are given and both are represented by piecewise polylines, with the ego vehicle&amp;rsquo;s shape represented by enclosing circles, there is a need to frequently check if a circle intersects a polyline segment, or the distance between the circle and the polyline. This can be computationally expensive. One alternative approach is to assume a circle rolls from the start point of the polyline to the endpoint. The trajectory traced by the circle’s center will form a new boundary. Subsequently, we only need to ensure that the center of the ego vehicle&amp;rsquo;s enclosing circle remains inside this new boundary.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Convex Corridor Construction Method:&lt;/strong&gt;&lt;br&gt;
Constructing a convex corridor in path planning needs to be efficient while avoiding the loss of feasible space. For autonomous driving, the reference line can serve as a heuristic, where points are taken along the reference line at intervals and used as seeds to build the convex space.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Allocation and Switching of Convex Space Constraints:&lt;/strong&gt;&lt;br&gt;
It is possible that the convex space constraint for a given path point may differ between consecutive iterations. How can we switch constraints without affecting the convergence? The answer is that constraint switching should only occur from a larger violation of the constraint to a smaller one. For example, when switching convex space constraints, we need to evaluate the distance from the path point to the convex hull and only allow switching from a larger distance to a smaller one, but not the reverse.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ESDF Smoothing Method:&lt;/strong&gt;&lt;br&gt;
In path planning, if the ESDF is used to evaluate the distance to obstacles, and the ego vehicle’s shape is represented by enclosing circles, we observe that directly constructing the ESDF from the actual obstacle boundaries leads to many local minima. This issue can be alleviated by first expanding the obstacles according to the radius of the ego vehicle&amp;rsquo;s enclosing circle and then constructing the ESDF.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Frenet Distance Field Construction and Update Method:&lt;/strong&gt;&lt;br&gt;
Before constructing the Frenet distance field, simplify the reference line by reducing the original reference line to a piecewise polyline within a given error range. Then, calculate the distance field based on this polyline. The distance field is stored in blocks and is progressively updated as the vehicle moves forward.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;32-optimization-solving&#34;&gt;3.2 Optimization Solving&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Penalty Function Selection:&lt;/strong&gt;&lt;br&gt;
Exponential and log-based obstacle functions grow too quickly and can cause divergence during the iteration process. A polynomial-based obstacle function is a better choice, provided it is twice differentiable near zero.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Selection of Penalty Coefficients in Penalty Functions:&lt;/strong&gt;&lt;br&gt;
The penalty coefficient should not be set too large at the outset. It is better to gradually increase the penalty, which helps to avoid local minima when the initial solution quality is poor.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Trust Region Mechanism:&lt;/strong&gt;&lt;br&gt;
ILQR is a shooting-based algorithm, where small changes in control inputs can lead to large trajectory deviations due to the cumulative effects of the kinematic model. This can lead to instability in the iteration process or cause iterations to stagnate (because the step size must be very small). Therefore, it is necessary to constrain the range of control input changes. This can be done by adding regularization terms to the cost function or by directly enforcing constraints.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- ### 4 Results
The developed path planner completely replaces the Frenet-based path planner and has been fully implemented on the RoboTaxi of our company. --&gt;</description>
    </item>
    
    <item>
      <title>Autonomous Dynamic Hitch-Hiking Control of a Bionic Robotic Remora</title>
      <link>https://zhangpengfei.com/publication/dynamic-attach/</link>
      <pubDate>Sat, 04 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/publication/dynamic-attach/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Video&lt;/strong&gt;&lt;/p&gt;


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/Q82rk2gQv1w?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;!-- 




  
    
  

&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.&lt;/span&gt;
&lt;/div&gt;






  
    
  

&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.&lt;/span&gt;
&lt;/div&gt;

Add the publication&#39;s **full text** or **supplementary notes** here. You can use rich formatting such as including [code, math, and images](https://docs.hugoblox.com/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Distributed Formation Control for a Multirobotic Fish System With Model-Based Event-Triggered Communication Mechanism</title>
      <link>https://zhangpengfei.com/publication/tie2023/</link>
      <pubDate>Wed, 04 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/publication/tie2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning for Depth Control of a Robotic Penguin: A Data-Driven Model Predictive Control Approach</title>
      <link>https://zhangpengfei.com/publication/tie2022panjie/</link>
      <pubDate>Tue, 06 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/publication/tie2022panjie/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bionic Robotic Remora</title>
      <link>https://zhangpengfei.com/post/email/</link>
      <pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/post/email/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bionic Robotic Remora</title>
      <link>https://zhangpengfei.com/project/robotic_remora/</link>
      <pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/project/robotic_remora/</guid>
      <description>&lt;h3 id=&#34;1-background&#34;&gt;1 Background&lt;/h3&gt;
&lt;p&gt;Biomimetic robotic fish, by imitating the shape and oscillatory propulsion mechanism of real fish, exhibit numerous advantages such as high mobility, minimal environmental disturbance, and strong concealment, making them a new type of underwater robot with significant research value and broad application prospects. However, under current energy technology conditions, the energy that robotic fish can carry is limited, making it difficult to perform long-distance, long-duration, and large-scale marine tasks. Therefore, enhancing the endurance of robotic fish has become a critical issue that needs to be addressed.&lt;/p&gt;
&lt;p&gt;In nature, the hitch-hiking behavior of remora fish provides inspiration for solving this problem. Remora fish attach themselves to larger fish or marine animals using their dorsal suckers, and rely on the host’s movement to travel long distances and feed. Although the remora fish itself has poor swimming ability, it can migrate and navigate between different marine areas due to its unique adhesion ability. Inspired by this, combining the adhesion mechanism with the fish-like swimming method, we have developed an adhesive bionic robotic remora. By utilizing the hitch-hiking behavior, the robotic fish can reduce energy consumption, potentially greatly improving its endurance. Additionally, the adhesive function has potential applications in multi-robot systems and covert reconnaissance tasks for specific targets.&lt;/p&gt;
&lt;p&gt;Based on the above background, this project aims to develop a novel adhesive bionic robotic remora and achieve fully autonomous adhesion tasks. In pursuit of this goal, the project focuses on the following aspects: system design and modeling of the adhesive bionic robotic remora, underwater visual localization based on artificial markers and refraction correction, and autonomous adhesion control for static and moving targets. The specific framework is shown in the figure below.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/framework_eng_hu10781461566864670092.webp 400w,
               /media/framework_eng_hu10529548567239872628.webp 760w,
               /media/framework_eng_hu11975369598886741319.webp 1200w&#34;
               src=&#34;https://zhangpengfei.com/media/framework_eng_hu10781461566864670092.webp&#34;
               width=&#34;760&#34;
               height=&#34;452&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;2-innovative-achievements&#34;&gt;2 Innovative Achievements&lt;/h3&gt;
&lt;h4 id=&#34;21-system-design-and-modeling-of-adhesive-bionic-robotic-remora&#34;&gt;2.1 System Design and Modeling of Adhesive Bionic Robotic Remora&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The world’s first prototype of an adhesive biomimetic robotic remora was developed, including the design of the electromechanical system, low-level motion control software, and upper-level graphical user interface. Specifically, the robotic fish includes four main systems: the motion system, perception system, adhesion system, and communication system. Innovations were made in each of these systems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Motion System&lt;/strong&gt;: Designed omnidirectional pectoral fin joints and a compact buoyancy adjustment device, endowing the robotic fish with exceptional 3D mobility.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Perception System&lt;/strong&gt;: Developed a binocular perception system with an active gimbal structure, enabling large-scale underwater environmental perception.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Adhesion System&lt;/strong&gt;: Optimized the hardness and shape of the biomimetic sucker and designed a system with both perception and active adhesion capabilities.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Communication System&lt;/strong&gt;: Designed and implemented the RFLink communication protocol for underwater multi-robot communication, ensuring accurate and efficient data transmission.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/robotremora_eng1_hu8634535401637021243.webp 400w,
               /media/robotremora_eng1_hu8842555846011831338.webp 760w,
               /media/robotremora_eng1_hu15977198897621415249.webp 1200w&#34;
               src=&#34;https://zhangpengfei.com/media/robotremora_eng1_hu8634535401637021243.webp&#34;
               width=&#34;760&#34;
               height=&#34;446&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/robotremora_eng2_hu1901520609089256998.webp 400w,
               /media/robotremora_eng2_hu8215387401209067480.webp 760w,
               /media/robotremora_eng2_hu3974156986486722329.webp 1200w&#34;
               src=&#34;https://zhangpengfei.com/media/robotremora_eng2_hu1901520609089256998.webp&#34;
               width=&#34;760&#34;
               height=&#34;167&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The 3D dynamic model of the robotic fish was completed, along with a visualized 3D motion simulation environment. Specifically, the following work was completed:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Dynamic Modeling&lt;/strong&gt;: Using the Newton-Euler method, the dynamic models of the robotic fish body and buoyancy adjustment device were created. A quasi-steady lift-drag model and the Lighthill’s large amplitude elongated body theory, were used to analyze the forces on static and oscillating fins, ultimately resulting in a complete 3D motion model.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;3D Motion Simulation&lt;/strong&gt;: A visualized 3D motion simulation environment was developed based on the derived kinematic model. Actual motion data from the robotic fish was used for parameter identification. The developed simulation environment exhibits high fidelity and can even reproduce advanced maneuvers such as spiral descents, forward flips, and horizontal rolls.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;22-underwater-visual-localization-based-on-artificial-markers-and-refraction-correction&#34;&gt;2.2 Underwater Visual Localization Based on Artificial Markers and Refraction Correction&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Designed and implemented an underwater stereo visual-inertial localization algorithm based on ArUco markers. This algorithm provides accurate positioning information for the robotic fish’s autonomous adhesion tasks, with the following features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The system analyzed the refraction model and imaging characteristics of the flat waterproof cover. The position and orientation estimation method for ArUco markers was re-derived and designed for taking into account the refraction distortion effects.&lt;/li&gt;
&lt;li&gt;Using an error-state Kalman filter framework, IMU raw data and ArUco marker pose estimation results were fused to obtain more stable and precise position estimates for the robotic fish.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/fbusekf-eng_hu12104914246744742866.webp 400w,
               /media/fbusekf-eng_hu6888453251909266627.webp 760w,
               /media/fbusekf-eng_hu10441138505897959003.webp 1200w&#34;
               src=&#34;https://zhangpengfei.com/media/fbusekf-eng_hu12104914246744742866.webp&#34;
               width=&#34;760&#34;
               height=&#34;285&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Designed and implemented an underwater fish-eye visual localization method based on LED markers. This algorithm also provides precise positioning information for the robotic fish’s autonomous adhesion tasks, with the following features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An image recognition and pattern matching algorithm was developed for LED markers, enabling rapid and stable detection of markers and the determination of matching relationships for feature points.&lt;/li&gt;
&lt;li&gt;The system analyzed the refraction model and imaging characteristics of spherical waterproof covers and used DLT and LM algorithms to optimize the pose estimation of LED markers.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/fisheye-eng_hu9322959121027703173.webp 400w,
               /media/fisheye-eng_hu2019401629071277480.webp 760w,
               /media/fisheye-eng_hu7823362175535397090.webp 1200w&#34;
               src=&#34;https://zhangpengfei.com/media/fisheye-eng_hu9322959121027703173.webp&#34;
               width=&#34;760&#34;
               height=&#34;202&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;23-autonomous-adhesion-control-for-floating-targets&#34;&gt;2.3 Autonomous Adhesion Control for Floating Targets&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Designed an autonomous adhesion control strategy based on a finite-state machine, describing the process of autonomous adhesion to floating targets as six states: cruising search, target approach, pose adjustment, adhesion control, adhesion maintenance, and detachment control. Motion controllers for each sub-state were designed and implemented in a physical robotic fish prototype. Related results were published in &lt;em&gt;IEEE Transactions on Mechatronics&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Proposed a planar position control algorithm based on tail fin driving, establishing a planar averaged dynamic model for tail-driven robotic fish. A orientation-velocity control objective with velocity constraints was designed, and a nonlinear model predictive control approach was used to solve for the final control inputs. The proposed algorithm was validated in a simulation environment, demonstrating its ability to effectively overcome the challenges posed by the robotic fish’s underactuated characteristics and achieve stable and precise position control. The related results were published in &lt;em&gt;Nonlinear Dynamics&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Proposed a planar pose control algorithm based on pectoral fin mode switching. The control process was divided into two phases: path tracking and fine adjustment. During the path tracking phase, virtual paths and mode-holding regions were introduced to enable fast convergence of lateral position and heading errors. In the fine adjustment phase, a hyperbolic tangent function was used to adjust the amplitude of pectoral fin oscillation, ensuring convergence of the longitudinal position error.
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/posecontrol_eng_hu12082468083607114346.webp 400w,
               /media/posecontrol_eng_hu7147867203461936143.webp 760w,
               /media/posecontrol_eng_hu6290407583995814536.webp 1200w&#34;
               src=&#34;https://zhangpengfei.com/media/posecontrol_eng_hu12082468083607114346.webp&#34;
               width=&#34;760&#34;
               height=&#34;532&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Proposed a depth control algorithm based on a nonlinear disturbance observer. A vertical motion model based on the buoyancy adjustment device was established, and feedback linearization and disturbance observation techniques were used to design a depth controller.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;24-autonomous-adhesion-control-for-moving-targets&#34;&gt;2.4 Autonomous Adhesion Control for Moving Targets&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Designed an autonomous adhesion control strategy based on a finite-state machine, describing the process of autonomous adhesion to moving targets as five states: cruising search, target tracking, synchronized adhesion, adhesion maintenance, and detachment control. Motion controllers for each sub-state were designed and implemented in a physical robotic fish prototype. Related results were published in &lt;em&gt;IEEE Transactions on Industrial Electronics&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/dynamictarget_eng_hu1346718025489858153.webp 400w,
               /media/dynamictarget_eng_hu2683439177328850172.webp 760w,
               /media/dynamictarget_eng_hu18095122616151611045.webp 1200w&#34;
               src=&#34;https://zhangpengfei.com/media/dynamictarget_eng_hu1346718025489858153.webp&#34;
               width=&#34;575&#34;
               height=&#34;282&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Proposed a multi-modal motion-based planar state synchronization control algorithm. Given the underactuated characteristics of the robotic fish, the control was decomposed into lateral and longitudinal control. Lateral control employed line-of-sight navigation to track the heading of the moving target with the tail fin, while longitudinal control simplified the system to a second-order integrator model with external disturbances. A sliding mode controller was designed for controlling the pectoral fins, ensuring that the position and velocity of the robotic fish converged to the moving target.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-videos&#34;&gt;3 Videos&lt;/h3&gt;
&lt;h4 id=&#34;31-nonlinear-model-predictive-position-control&#34;&gt;3.1 Nonlinear Model Predictive Position Control&lt;/h4&gt;


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/MO9XiuvL5N8?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h4 id=&#34;32-underwater-stereo-visual-inertial-localization&#34;&gt;3.2 Underwater Stereo Visual-Inertial Localization&lt;/h4&gt;


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/vcK99HpPWEs?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h4 id=&#34;33-autonomous-hitch-hiking-behaviors-for-stationary-hosts&#34;&gt;3.3 Autonomous hitch-hiking behaviors for stationary hosts&lt;/h4&gt;


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/1YwS2vIkxRs?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h4 id=&#34;34-autonomous-hitch-hiking-behaviors-for-moving-hosts&#34;&gt;3.4 Autonomous hitch-hiking behaviors for moving hosts&lt;/h4&gt;


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/Q82rk2gQv1w?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h3 id=&#34;4-publications&#34;&gt;4 Publications&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pengfei Zhang&lt;/strong&gt;, Zhengxing Wu, Yan Meng, Min Tan, Junzhi Yu. &lt;strong&gt;Nonlinear Model Predictive Position Control for a Tail-Actuated Robotic Fish&lt;/strong&gt;. &lt;em&gt;IEEE Transactions on Mechatronics&lt;/em&gt;. 2020.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pengfei Zhang&lt;/strong&gt;, Zhengxing Wu, Jian Wang, Shihan Kong, Min Tan, Junzhi Yu. &lt;strong&gt;An Open-Source, Fiducial-Based, Underwater Stereo Visual-Inertial Localization Method with Refraction Correction&lt;/strong&gt;. In &lt;em&gt;2021 IEEE/RSJ International Conference on Intelligent Robots and Systems&lt;/em&gt;. 2021&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pengfei Zhang&lt;/strong&gt;, Zhengxing Wu, Yan Meng, Huijie Dong, Min Tan, Junzhi Yu. &lt;strong&gt;Development and Control of a Bioinspired Robotic Remora for Hitchhiking&lt;/strong&gt;. &lt;em&gt;IEEE Transactions on Mechatronics&lt;/em&gt;. 2021.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pengfei Zhang&lt;/strong&gt;, Zhengxing Wu, Di Chen, Min Tan, Junzhi Yu (2023). &lt;strong&gt;Autonomous Dynamic Hitch-Hiking Control of a Bionic Robotic Remora&lt;/strong&gt;. &lt;em&gt;IEEE Transactions on Industrial Electronics&lt;/em&gt;. 2023.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Development of a Penguin-Inspired Swimming Robot With Air Lubrication System</title>
      <link>https://zhangpengfei.com/publication/tie2022/</link>
      <pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/publication/tie2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Real-Time Digital Video Stabilization of Bioinspired Robotic Fish Using Estimation-and-Prediction Framework</title>
      <link>https://zhangpengfei.com/publication/tmech2022/</link>
      <pubDate>Mon, 14 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/publication/tmech2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Performance Improvement of a High-Speed Swimming Robot for Fish-Like Leaping</title>
      <link>https://zhangpengfei.com/publication/ral2022/</link>
      <pubDate>Thu, 13 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/publication/ral2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Development and Control of a Bioinspired Robotic Remora for Hitchhiking</title>
      <link>https://zhangpengfei.com/publication/static-attach/</link>
      <pubDate>Thu, 04 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/publication/static-attach/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Video&lt;/strong&gt;&lt;/p&gt;


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/1YwS2vIkxRs?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;!-- 




  
    
  

&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.&lt;/span&gt;
&lt;/div&gt;






  
    
  

&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.&lt;/span&gt;
&lt;/div&gt;

Add the publication&#39;s **full text** or **supplementary notes** here. You can use rich formatting such as including [code, math, and images](https://docs.hugoblox.com/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Separate Control Strategy for a Biomimetic Gliding Robotic Fish</title>
      <link>https://zhangpengfei.com/publication/tmech2021/</link>
      <pubDate>Tue, 19 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/publication/tmech2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An Open-Source, Fiducial-Based, Underwater Stereo Visual-Inertial Localization Method with Refraction Correction</title>
      <link>https://zhangpengfei.com/publication/fbus-ekf/</link>
      <pubDate>Mon, 27 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/publication/fbus-ekf/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Video&lt;/strong&gt;&lt;/p&gt;


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/vcK99HpPWEs?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;!-- 




  
    
  

&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.&lt;/span&gt;
&lt;/div&gt;






  
    
  

&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.&lt;/span&gt;
&lt;/div&gt;

Add the publication&#39;s **full text** or **supplementary notes** here. You can use rich formatting such as including [code, math, and images](https://docs.hugoblox.com/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Nonlinear Model Predictive Position Control for a Tail-Actuated Robotic Fish</title>
      <link>https://zhangpengfei.com/publication/nonlinear-controller/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/publication/nonlinear-controller/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Video&lt;/strong&gt;


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/MO9XiuvL5N8?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;
&lt;/p&gt;
&lt;!-- 




  
    
  

&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.&lt;/span&gt;
&lt;/div&gt;






  
    
  

&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.&lt;/span&gt;
&lt;/div&gt;

Add the publication&#39;s **full text** or **supplementary notes** here. You can use rich formatting such as including [code, math, and images](https://docs.hugoblox.com/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Robotic Fish with Reaction Wheel</title>
      <link>https://zhangpengfei.com/project/attitude_stability/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/project/attitude_stability/</guid>
      <description>&lt;h2 id=&#34;1-background&#34;&gt;1 Background&lt;/h2&gt;
&lt;p&gt;The propulsion mechanism of the bionic robotic fish, which generates thrust through the reciprocal swinging motion of the fish body, inevitably causes instability in the robot&amp;rsquo;s attitude. Among these, the periodic oscillation of the yaw angle and roll angle is particularly severe. The oscillation in attitude leads to fluctuations in the sensor data of the robotic fish, which can significantly degrade the quality of image data (motion blur), creating major challenges for the robot environmental perception. Based on this background, this project focuses on two areas of research: fish body attitude stabilization technology and sensor attitude stabilization technology.&lt;/p&gt;
&lt;h2 id=&#34;2-innovative-achievements&#34;&gt;2 Innovative Achievements&lt;/h2&gt;
&lt;h3 id=&#34;21-roll-stabilization-control-for-robotic-fish-based-on-reaction-wheel&#34;&gt;2.1 Roll Stabilization Control for Robotic Fish Based on Reaction Wheel&lt;/h3&gt;


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/BsRtjJycxns?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Designed and manufactured the first multi-joint robotic fish equipped with a reaction wheel, and developed the corresponding low-level control software and graphical user interface to validate the effectiveness of roll angle stabilization control technology.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/reactionwheel_hu5248344090936938935.webp 400w,
               /media/reactionwheel_hu13238156557407522315.webp 760w,
               /media/reactionwheel_hu14102446649243838678.webp 1200w&#34;
               src=&#34;https://zhangpengfei.com/media/reactionwheel_hu5248344090936938935.webp&#34;
               width=&#34;760&#34;
               height=&#34;436&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Based on the Newton-Euler method, a dynamic model of the robotic fish body combined with the reaction wheel was established. By making simplifying assumptions, a roll angle dynamic model was derived.&lt;/li&gt;
&lt;li&gt;The dynamic characteristics of the roll angle model were analyzed in detail. The advantages and disadvantages of various roll angle stabilization methods, including optimizing mass distribution (e.g., increasing the distance between the center of mass and the center of buoyancy), increasing damping coefficients (e.g., enlarging the pectoral fin area), and applying reaction torques, were theoretically discussed.&lt;/li&gt;
&lt;li&gt;A Sliding Mode Controller (SMC) with neural network feedforward was designed. The multi-layer perceptron was used to fit the disturbances caused by the fish body’s oscillation on the roll angle, which were then compensated as feedforward. The sliding mode controller further suppressed disturbances from external environments and estimation errors, achieving more reliable roll angle stabilization control.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/reactionwheelcontrol_hu641808666216467070.webp 400w,
               /media/reactionwheelcontrol_hu7705363361785188979.webp 760w,
               /media/reactionwheelcontrol_hu7472311285269510299.webp 1200w&#34;
               src=&#34;https://zhangpengfei.com/media/reactionwheelcontrol_hu641808666216467070.webp&#34;
               width=&#34;760&#34;
               height=&#34;422&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Related research results were published in &lt;em&gt;IEEE Transactions on Mechatronics&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;22-two-dof-camera-gimbal-for-robotic-fish-applications&#34;&gt;2.2 Two-DoF Camera Gimbal for Robotic Fish Applications&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Designed a miniaturized two-DoF camera gimbal for robotic fish applications, capable of stabilizing the camera’s attitude in both yaw and roll directions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/gimbal_hu11342021533249767498.webp 400w,
               /media/gimbal_hu1051715823169329251.webp 760w,
               /media/gimbal_hu13382338844221121420.webp 1200w&#34;
               src=&#34;https://zhangpengfei.com/media/gimbal_hu11342021533249767498.webp&#34;
               width=&#34;760&#34;
               height=&#34;506&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Developed the forward and inverse kinematics of the gimbal to compute control targets. A stabilizing controller based on Active Disturbance Rejection Control (ADRC) was designed and validated on a physical platform, demonstrating better control performance than PID.&lt;/li&gt;
&lt;li&gt;Related research results were published in the &lt;em&gt;IEEE International Conference on CYBER Technology in Automation, Control, and Intelligent Systems&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3-publications&#34;&gt;3 Publications&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pengfei Zhang&lt;/strong&gt;, Zhengxing Wu, Huijie Dong, Min Tan, Junzhi Yu. &lt;strong&gt;Reaction-Wheel-Based Roll Stabilization for a Robotic Fish Using Neural Network Sliding Mode Control&lt;/strong&gt;. &lt;em&gt;IEEE Transactions on Mechatronics&lt;/em&gt;. 2020.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pengfei Zhang&lt;/strong&gt;, Zhengxing Wu, Jian Wang, Min Tan, Junzhi Yu. &lt;strong&gt;2-DOF camera stabilization platform for robotic fish based on active disturbance rejection control&lt;/strong&gt;. &lt;em&gt;IEEE International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)&lt;/em&gt;. 2019.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Reaction-Wheel-Based Roll Stabilization for a Robotic Fish Using Neural Network Sliding Mode Control</title>
      <link>https://zhangpengfei.com/publication/reaction-wheel/</link>
      <pubDate>Mon, 04 May 2020 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/publication/reaction-wheel/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Video&lt;/strong&gt;&lt;/p&gt;


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/BsRtjJycxns?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;!-- 




  
    
  

&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.&lt;/span&gt;
&lt;/div&gt;






  
    
  

&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.&lt;/span&gt;
&lt;/div&gt;

Add the publication&#39;s **full text** or **supplementary notes** here. You can use rich formatting such as including [code, math, and images](https://docs.hugoblox.com/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Underwater Target Tracking Control of an Untethered Robotic Fish With a Camera Stabilizer</title>
      <link>https://zhangpengfei.com/publication/smc2020/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/publication/smc2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>2-DOF Camera Stabilization Platform for Robotic Fish Based on Active Disturbance Rejection Control</title>
      <link>https://zhangpengfei.com/publication/gimbal/</link>
      <pubDate>Sat, 28 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://zhangpengfei.com/publication/gimbal/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
